SmartTVKeyboard
Smart TV Predictive Numeric Keyboard
A remote-optimized text input system using a 12-key numeric layout with predictive typing, designed to work seamlessly across multiple input devices including D-pad remotes, keyboards, and gaming controllers.

This project explores how legacy numeric input models can be re-designed for modern large-screen and living-room contexts to reduce time-to-content, navigation effort, and input errors across different interaction modes.

Problem Statement
Text entry on Smart TVs and large-screen devices remains one of the slowest and most frustrating interactions:

D-pad navigation across QWERTY grids is tedious
High error rates due to overshooting and poor focus visibility
Long time-to-search impacts content discovery
Gaming controllers and hybrid remotes introduce inconsistent input behaviors
This project investigates whether a predictive numeric keyboard can significantly improve:

Speed of input
Cross-device ergonomics
Learnability across controllers
Visual focus management
Key Concepts
12-key numeric layout adaptable across input devices
Predictive word suggestions based on partial key sequences
Unified navigation model for:
D-pad remotes
Physical keyboards
Gaming controllers / joysticks
Focus-first interaction for large-screen environments
Minimal visual noise for couch-distance readability
Features
Numeric multi-letter key mapping
Real-time predictive suggestions
Multi-input support:
Directional remotes (D-pad)
Physical / virtual keyboards
Game controllers and joysticks
Error-tolerant input flow
Optimized for:
Living room distance
One-hand interaction
Thumb-driven navigation
Tech / Stack
Frontend: [Your framework / vanilla JS / React etc.]
Input handling: Unified abstraction layer for remote, keyboard, and controller events
Input logic: Custom predictive mapping
Platform target: Smart TV / Web / Emulator
Design & UX Rationale
This project is built as a UX-driven interaction system design exercise focusing on:

Cross-input consistency (remote, keyboard, controller)
Remote ergonomics and thumb reach
Focus management on large screens
Reduction of cognitive load vs QWERTY grids
Input modality independence as a core design principle
Time-to-first-character and time-to-search as primary success metrics
AI Assistance Disclosure
Some portions of this project were assisted by AI tools for ideation and implementation support.
All interaction design, system architecture, UX decisions, and final implementation are authored and integrated by the project owner.

License
This project is licensed under the MIT License.
You are free to use, modify, and distribute this code with attribution.

Author
Karan Dhiman
Product / UX Designer
Bangalore, India

Disclaimer
This project is an independent UX and technical exploration.
It is not affiliated with, endorsed by, or derived from any proprietary T9 or predictive text system.

All algorithms, layouts, navigation models, and behaviors are original implementations inspired by general public-domain input patterns and modern multi-device interaction principles.
